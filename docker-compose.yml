version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    environment:
      - PYTHONPATH=/app
      # AI_FALLBACK_MODE is now auto-detected based on GPU availability
      # You can still override it by uncommenting the line below
      # - AI_FALLBACK_MODE=true
      - MISTRAL_API_URL=http://ai-service:80

  # AI service configuration for CPU-only environments (mock service)
  # The real service will only be used if GPU is available (detected by backend)
  ai-service:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./backend/app/services/ai/mock_service:/usr/share/nginx/html
    # Simple healthcheck that always passes
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:80/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

volumes:
  ai-model-data:
